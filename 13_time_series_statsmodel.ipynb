{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13_time_series_statsmodel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayaz-ncr/100ml/blob/master/13_time_series_statsmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc1OnhE3oR58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR0bSxJ6oVUU",
        "colab_type": "text"
      },
      "source": [
        "1. Autoregression (AR)\n",
        "2. Moving Average (MA)\n",
        "3. Autoregressive Moving Average (ARMA)\n",
        "4. Autoregressive Integrated Moving Average (ARIMA)\n",
        "5. Seasonal Autoregressive Integrated Moving-Average (SARIMA)\n",
        "6. Seasonal Autoregressive Integrated Moving-Average with Exogenous Regressors (SARIMAX)\n",
        "7. Vector Autoregression (VAR)\n",
        "8. Vector Autoregression Moving-Average (VARMA)\n",
        "9. Vector Autoregression Moving-Average with Exogenous Regressors (VARMAX)\n",
        "10. Simple Exponential Smoothing (SES)\n",
        "11. Holt Winterâ€™s Exponential Smoothing (HWES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-8HdI5rorev",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwB_Krf_oXEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a9e1801-384d-4899-b96f-c1f9b4b95538"
      },
      "source": [
        "# Auto Regression example\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from random import random\n",
        "# contrived dataset\n",
        "data = [x + random() for x in range(1, 100)]\n",
        "# fit model\n",
        "model = AR(data)\n",
        "model_fit = model.fit()\n",
        "# make prediction\n",
        "yhat = model_fit.predict(len(data), len(data))\n",
        "print(yhat)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[100.39887657]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T06pFCWppEsv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09686e08-5d29-43b2-f529-9d905006237e"
      },
      "source": [
        "# MA example\n",
        "from statsmodels.tsa.arima_model import ARMA\n",
        "from random import random\n",
        "# contrived dataset\n",
        "data = [x + random() for x in range(1, 100)]\n",
        "# fit model\n",
        "model = ARMA(data, order=(0, 1))\n",
        "model_fit = model.fit(disp=False)\n",
        "# make prediction\n",
        "yhat = model_fit.predict(len(data), len(data))\n",
        "print(yhat)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[74.4366721]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yy-ZMA8pLSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32033199-1ba4-449a-dfaf-b9ae72be816b"
      },
      "source": [
        "# ARMA example\n",
        "from statsmodels.tsa.arima_model import ARMA\n",
        "from random import random\n",
        "# contrived dataset\n",
        "data = [random() for x in range(1, 100)]\n",
        "# fit model\n",
        "model = ARMA(data, order=(2, 1))\n",
        "model_fit = model.fit(disp=False)\n",
        "# make prediction\n",
        "yhat = model_fit.predict(len(data), len(data))\n",
        "print(yhat)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.45365509]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEfz6po_pnlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e015eac-26cc-450c-8a90-40c9fe199bf9"
      },
      "source": [
        "# ARIMA example\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from random import random\n",
        "# contrived dataset\n",
        "data = [x + random() for x in range(1, 100)]\n",
        "# fit model\n",
        "model = ARIMA(data, order=(1, 1, 1))\n",
        "model_fit = model.fit(disp=False)\n",
        "# make prediction\n",
        "yhat = model_fit.predict(len(data), len(data), typ='levels')\n",
        "print(yhat)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[100.53862512]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjUkTzpYpq3m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6329d95d-8177-41a5-e7ef-8765fac5cbc1"
      },
      "source": [
        "# SARIMA example\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from random import random\n",
        "# contrived dataset\n",
        "data = [x + random() for x in range(1, 100)]\n",
        "# fit model\n",
        "model = SARIMAX(data, order=(1, 1, 1), seasonal_order=(1, 1, 1, 1))\n",
        "model_fit = model.fit(disp=False)\n",
        "# make prediction\n",
        "yhat = model_fit.predict(len(data), len(data))\n",
        "print(yhat)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[100.46629239]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evg4g0qGpupj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "519b97b3-2c64-42b0-9e31-18dfc09a5770"
      },
      "source": [
        "# SARIMAX example\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from random import random\n",
        "# contrived dataset\n",
        "data1 = [x + random() for x in range(1, 100)]\n",
        "data2 = [x + random() for x in range(101, 200)]\n",
        "# fit model\n",
        "model = SARIMAX(data1, exog=data2, order=(1, 1, 1), seasonal_order=(0, 0, 0, 0))\n",
        "model_fit = model.fit(disp=False)\n",
        "# make prediction\n",
        "exog2 = [200 + random()]\n",
        "yhat = model_fit.predict(len(data1), len(data1), exog=[exog2])\n",
        "print(yhat)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[100.79583192]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIB2Mchrp0d5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1742ec4-244d-4a42-cceb-932f305ed6a2"
      },
      "source": [
        "# VAR example\n",
        "from statsmodels.tsa.vector_ar.var_model import VAR\n",
        "from random import random\n",
        "# contrived dataset with dependency\n",
        "data = list()\n",
        "for i in range(100):\n",
        "  v1 = i + random()\n",
        "  v2 = v1 + random()\n",
        "  row = [v1, v2]\n",
        "  data.append(row)\n",
        "# fit model\n",
        "model = VAR(data)\n",
        "model_fit = model.fit()\n",
        "# make prediction\n",
        "yhat = model_fit.forecast(model_fit.y, steps=1)\n",
        "print(yhat)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[101.07861517 101.48814738]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS0Oh1BFp-NW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "e4ee74c0-8118-4db1-b170-abfe4eeef7c8"
      },
      "source": [
        "# VARMA example\n",
        "from statsmodels.tsa.statespace.varmax import VARMAX\n",
        "from random import random\n",
        "# contrived dataset with dependency\n",
        "data = list()\n",
        "for i in range(100):\n",
        "  v1 = random()\n",
        "  v2 = v1 + random()\n",
        "  row = [v1, v2]\n",
        "  data.append(row)\n",
        "# fit model\n",
        "model = VARMAX(data, order=(1, 1))\n",
        "model_fit = model.fit(disp=False)\n",
        "# make prediction\n",
        "yhat = model_fit.forecast()\n",
        "print(yhat)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tsa/statespace/varmax.py:152: EstimationWarning: Estimation of VARMA(p,q) models is not generically robust, due especially to identification issues.\n",
            "  EstimationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tsa/statespace/representation.py:375: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  return matrix[[slice(None)]*(matrix.ndim-1) + [0]]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.46802745 0.9323294 ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tsa/statespace/varmax.py:152: EstimationWarning: Estimation of VARMA(p,q) models is not generically robust, due especially to identification issues.\n",
            "  EstimationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1DOA2usqHGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "d4a7f4e0-643a-4e77-a81f-c497fac4bbdd"
      },
      "source": [
        "# VARMA example\n",
        "from statsmodels.tsa.statespace.varmax import VARMAX\n",
        "from random import random\n",
        "# contrived dataset with dependency\n",
        "data = list()\n",
        "for i in range(100):\n",
        "  v1 = random()\n",
        "  v2 = v1 + random()\n",
        "  row = [v1, v2]\n",
        "  data.append(row)\n",
        "# fit model\n",
        "model = VARMAX(data, order=(1, 1))\n",
        "model_fit = model.fit(disp=False)\n",
        "# make prediction\n",
        "yhat = model_fit.forecast()\n",
        "print(yhat)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tsa/statespace/varmax.py:152: EstimationWarning: Estimation of VARMA(p,q) models is not generically robust, due especially to identification issues.\n",
            "  EstimationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tsa/statespace/representation.py:375: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  return matrix[[slice(None)]*(matrix.ndim-1) + [0]]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.4960031  1.02686329]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/base/model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  \"Check mle_retvals\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tsa/statespace/varmax.py:152: EstimationWarning: Estimation of VARMA(p,q) models is not generically robust, due especially to identification issues.\n",
            "  EstimationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJpX2SRbqLfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f641087c-0be9-4bf1-a604-17596f87dc28"
      },
      "source": [
        "# SES example\n",
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
        "from random import random\n",
        "# contrived dataset\n",
        "data = [x + random() for x in range(1, 100)]\n",
        "# fit model\n",
        "model = SimpleExpSmoothing(data)\n",
        "model_fit = model.fit()\n",
        "# make prediction\n",
        "yhat = model_fit.predict(len(data), len(data))\n",
        "print(yhat)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[99.06066819]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Cqz-Fz0qPuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0114b6b-a539-4ce4-d4d3-774305d09123"
      },
      "source": [
        "# HWES example\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "from random import random\n",
        "# contrived dataset\n",
        "data = [x + random() for x in range(1, 100)]\n",
        "# fit model\n",
        "model = ExponentialSmoothing(data)\n",
        "model_fit = model.fit()\n",
        "# make prediction\n",
        "yhat = model_fit.predict(len(data), len(data))\n",
        "print(yhat)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[99.12553662]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}